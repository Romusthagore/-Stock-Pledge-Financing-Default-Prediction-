{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f9bd89c",
   "metadata": {
    "papermill": {
     "duration": 0.003895,
     "end_time": "2025-03-10T17:25:30.577737",
     "exception": false,
     "start_time": "2025-03-10T17:25:30.573842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"text-align:center; color:#4CAF50; font-size:36px; font-weight:bold;\">\n",
    "     Kaggle Competition: \n",
    "    <a href=\"https://www.kaggle.com/competitions/stock-pledge-financing-default-prediction/overview\" target=\"_blank\" style=\"color:#4CAF50; text-decoration:none;\">\n",
    "        Stock Pledge Financing Default Prediction\n",
    "    </a>\n",
    "</h1>\n",
    "\n",
    "<p style=\"font-size:18px; line-height:1.6; color:#333;\">\n",
    "    Welcome to my solution for the <b>Stock Pledge Financing Default Prediction</b> competition on Kaggle!  \n",
    "    This notebook outlines a comprehensive machine learning pipeline designed to predict the likelihood of default in stock pledge financing—a scenario where major shareholders use their equity holdings as collateral for loans. \n",
    "    Accurately forecasting such defaults is crucial for financial institutions to manage risks effectively.\n",
    "</p>\n",
    "\n",
    "<hr style=\"border:1px solid #ccc; margin:20px 0;\">\n",
    "\n",
    "<h2 style=\"color:#FF5722; font-size:28px;\">Objective</h2>\n",
    "\n",
    "<p style=\"font-size:18px; line-height:1.6; color:#333;\">\n",
    "    The primary goal is to develop a robust model that predicts the probability of default in stock pledge financing arrangements. \n",
    "    The evaluation metric for this competition is the <b>F1 Score</b>, which balances precision and recall, making it particularly suitable for datasets with imbalanced classes.\n",
    "</p>\n",
    "\n",
    "<hr style=\"border:1px solid #ccc; margin:20px 0;\">\n",
    "\n",
    "<h2 style=\"color:#3F51B5; font-size:28px;\"> Notebook Overview</h2>\n",
    "\n",
    "<ol style=\"font-size:16px; color:#555; line-height:1.8;\">\n",
    "    <li><b> Data Processing</b>\n",
    "        <ul>\n",
    "            <li>Loading and cleaning the dataset.</li>\n",
    "            <li>Handling missing values and encoding categorical variables.</li>\n",
    "            <li>Ensuring consistent indexing and feature naming.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b>Model Training</b>\n",
    "        <ul>\n",
    "            <li>Utilizing <b>LightGBM</b>, renowned for its efficiency with large datasets.</li>\n",
    "            <li>Implementing <b>Stratified K-Fold Cross-Validation</b> to ensure robust performance.</li>\n",
    "            <li>Optimizing probability thresholds to maximize the F1 score.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b> Evaluation</b>\n",
    "        <ul>\n",
    "            <li>Assessing the model using metrics like <b>Log-loss</b> and <b>F1 Score</b>.</li>\n",
    "            <li>Identifying the optimal cutoff threshold for classification.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b>Submission</b>\n",
    "        <ul>\n",
    "            <li>Preparing the final submission file for Kaggle.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<hr style=\"border:1px solid #ccc; margin:20px 0;\">\n",
    "\n",
    "<h2 style=\"color:#009688; font-size:28px;\"> Why LightGBM?</h2>\n",
    "\n",
    "<ul style=\"font-size:16px; color:#555; line-height:1.8;\">\n",
    "    <li><b>Speed</b>: It's one of the fastest gradient boosting frameworks available.</li>\n",
    "    <li><b>Performance</b>: Often achieves high accuracy with minimal tuning.</li>\n",
    "    <li><b>Flexibility</b>: Easily handles categorical features and missing values.</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"font-size:18px; line-height:1.6; color:#333;\">\n",
    "    Let's dive in and explore how this approach performs in predicting stock pledge financing defaults! \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1522cb53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T07:56:36.016829Z",
     "iopub.status.busy": "2025-03-10T07:56:36.016466Z",
     "iopub.status.idle": "2025-03-10T07:56:36.020666Z",
     "shell.execute_reply": "2025-03-10T07:56:36.019532Z",
     "shell.execute_reply.started": "2025-03-10T07:56:36.016799Z"
    },
    "papermill": {
     "duration": 0.003053,
     "end_time": "2025-03-10T17:25:30.584705",
     "exception": false,
     "start_time": "2025-03-10T17:25:30.581652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### ====================================================\n",
    "# Imports and Configurations\n",
    "#### ===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc7e260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T17:25:30.592467Z",
     "iopub.status.busy": "2025-03-10T17:25:30.592091Z",
     "iopub.status.idle": "2025-03-10T17:25:37.131898Z",
     "shell.execute_reply": "2025-03-10T17:25:37.130879Z"
    },
    "papermill": {
     "duration": 6.545906,
     "end_time": "2025-03-10T17:25:37.133820",
     "exception": false,
     "start_time": "2025-03-10T17:25:30.587914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, f1_score, precision_recall_curve, confusion_matrix\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Configurations\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c434c72f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T17:25:37.142218Z",
     "iopub.status.busy": "2025-03-10T17:25:37.141542Z",
     "iopub.status.idle": "2025-03-10T17:25:37.574569Z",
     "shell.execute_reply": "2025-03-10T17:25:37.573246Z"
    },
    "papermill": {
     "duration": 0.439086,
     "end_time": "2025-03-10T17:25:37.576483",
     "exception": false,
     "start_time": "2025-03-10T17:25:37.137397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/stock-pledge-defaults-prediction\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jiaoyouzhang/stock-pledge-defaults-prediction\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b626eaf0",
   "metadata": {
    "papermill": {
     "duration": 0.003028,
     "end_time": "2025-03-10T17:25:37.583005",
     "exception": false,
     "start_time": "2025-03-10T17:25:37.579977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### =======================================================================================\n",
    "#  Data Processing Section (Code)         \n",
    "#### ======================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63ceae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T17:25:37.591039Z",
     "iopub.status.busy": "2025-03-10T17:25:37.590631Z",
     "iopub.status.idle": "2025-03-10T17:25:37.679816Z",
     "shell.execute_reply": "2025-03-10T17:25:37.678616Z"
    },
    "papermill": {
     "duration": 0.095497,
     "end_time": "2025-03-10T17:25:37.681806",
     "exception": false,
     "start_time": "2025-03-10T17:25:37.586309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "target = \"IsDefault\"\n",
    "n_splits = 7  # Number of cross-validation splits\n",
    "\n",
    "# Load datasets\n",
    "train = pd.read_csv(f\"/kaggle/input/stock-pledge-defaults-prediction/train.csv\", index_col = \"Stock code\")\n",
    "test = pd.read_csv(f\"/kaggle/input/stock-pledge-defaults-prediction/test.csv\", index_col = \"Stock code\")\n",
    "\n",
    "# Initialize submission DataFrame\n",
    "sub_fl = pd.DataFrame(index=test.index, columns=[target], dtype=np.int8).fillna(0)\n",
    "\n",
    "# Separate features and target\n",
    "Xtrain = train.drop(columns=[target])\n",
    "ytrain = train[target]\n",
    "Xtest = test.copy()\n",
    "\n",
    "# Standardize column names\n",
    "for df in [Xtrain, Xtest]:\n",
    "    df.columns = [f\"col{i}\" for i in range(len(df.columns))]\n",
    "\n",
    "# Handle categorical columns\n",
    "cat_cols = Xtrain.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns\n",
    "Xtrain[cat_cols] = Xtrain[cat_cols].fillna(\"missing\").astype(\"category\")\n",
    "Xtest[cat_cols] = Xtest[cat_cols].fillna(\"missing\").astype(\"category\")\n",
    "\n",
    "# Reset indices\n",
    "Xtrain.index = range(len(Xtrain))\n",
    "ytrain.index = range(len(Xtrain))\n",
    "Xtest.index = range(len(Xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fb977c",
   "metadata": {
    "papermill": {
     "duration": 0.003002,
     "end_time": "2025-03-10T17:25:37.688274",
     "exception": false,
     "start_time": "2025-03-10T17:25:37.685272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### =======================================================================================\n",
    "#   Model Training with Cross-Validation (Code)  \n",
    "#### ======================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7286db97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T17:25:37.696074Z",
     "iopub.status.busy": "2025-03-10T17:25:37.695660Z",
     "iopub.status.idle": "2025-03-10T17:25:42.863352Z",
     "shell.execute_reply": "2025-03-10T17:25:42.862175Z"
    },
    "papermill": {
     "duration": 5.174071,
     "end_time": "2025-03-10T17:25:42.865590",
     "exception": false,
     "start_time": "2025-03-10T17:25:37.691519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ================== OFFLINE MODEL TRAINING ================== \n",
      "\n",
      "\n",
      " ============== FOLD 1 - LGBM ==============\n",
      "---> LGBM Log-loss = 0.03026621 | F1 raw = 0.96000000\n",
      "---> Best F1 = 0.98701299 | Best cutoff = 0.0500\n",
      "\n",
      " ============== FOLD 2 - LGBM ==============\n",
      "---> LGBM Log-loss = 0.00566426 | F1 raw = 0.98666667\n",
      "---> Best F1 = 1.00000000 | Best cutoff = 0.0800\n",
      "\n",
      " ============== FOLD 3 - LGBM ==============\n",
      "---> LGBM Log-loss = 0.00359298 | F1 raw = 1.00000000\n",
      "---> Best F1 = 1.00000000 | Best cutoff = 0.0500\n",
      "\n",
      " ============== FOLD 4 - LGBM ==============\n",
      "---> LGBM Log-loss = 0.00178036 | F1 raw = 1.00000000\n",
      "---> Best F1 = 1.00000000 | Best cutoff = 0.0500\n",
      "\n",
      " ============== FOLD 5 - LGBM ==============\n",
      "---> LGBM Log-loss = 0.00052280 | F1 raw = 1.00000000\n",
      "---> Best F1 = 1.00000000 | Best cutoff = 0.0500\n",
      "\n",
      " ============== FOLD 6 - LGBM ==============\n",
      "---> LGBM Log-loss = 0.00404107 | F1 raw = 1.00000000\n",
      "---> Best F1 = 1.00000000 | Best cutoff = 0.0500\n",
      "\n",
      " ============== FOLD 7 - LGBM ==============\n",
      "---> LGBM Log-loss = 0.00027447 | F1 raw = 1.00000000\n",
      "---> Best F1 = 1.00000000 | Best cutoff = 0.0500\n",
      "\n",
      "---> LGBM Overall F1 score = 0.99245283 | raw\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n ================== OFFLINE MODEL TRAINING ================== \\n\")\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "\n",
    "# Initialize arrays for predictions\n",
    "oof_preds_lgbm = np.zeros(len(Xtrain))\n",
    "mdl_preds_lgbm = np.zeros(len(Xtest))\n",
    "\n",
    "# Ensure column names are clean\n",
    "Xtrain.columns = Xtrain.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "Xtest.columns = Xtest.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "\n",
    "# Training loop\n",
    "for fold_nb, (train_idx, dev_idx) in enumerate(cv.split(Xtrain, ytrain)):\n",
    "    print(f\"\\n ============== FOLD {fold_nb+1} - LGBM ==============\")\n",
    "    \n",
    "    # Split data\n",
    "    Xtr, ytr = Xtrain.iloc[train_idx], ytrain.iloc[train_idx]\n",
    "    Xdev, ydev = Xtrain.iloc[dev_idx], ytrain.iloc[dev_idx]\n",
    "    \n",
    "    # Train model\n",
    "    lgbm_model = LGBMClassifier(n_estimators=450, random_state=42, verbose=-1)\n",
    "    lgbm_model.fit(Xtr, ytr)\n",
    "    \n",
    "    # Predictions\n",
    "    dev_preds = lgbm_model.predict_proba(Xdev)[:, 1]\n",
    "    test_preds = lgbm_model.predict_proba(Xtest)[:, 1]\n",
    "    \n",
    "    # Metrics\n",
    "    logloss = log_loss(ydev, dev_preds)\n",
    "    f1_raw = f1_score(ydev, np.round(dev_preds))\n",
    "    print(f\"---> LGBM Log-loss = {logloss:,.8f} | F1 raw = {f1_raw:,.8f}\")\n",
    "    \n",
    "    # Store predictions\n",
    "    oof_preds_lgbm[dev_idx] = dev_preds\n",
    "    mdl_preds_lgbm += test_preds / n_splits\n",
    "    \n",
    "    # Optimal threshold search\n",
    "    cutoffs = {cut: f1_score(ydev, np.where(dev_preds >= cut, 1, 0)) for cut in np.arange(0.05, 0.99, 0.01)}\n",
    "    best_cutoff = max(cutoffs, key=cutoffs.get)\n",
    "    best_f1 = cutoffs[best_cutoff]\n",
    "    print(f\"---> Best F1 = {best_f1:,.8f} | Best cutoff = {best_cutoff:,.4f}\")\n",
    "\n",
    "# Final evaluation\n",
    "final_f1_lgbm = f1_score(ytrain, np.round(oof_preds_lgbm, 0))\n",
    "print(f\"\\n---> LGBM Overall F1 score = {final_f1_lgbm:,.8f} | raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d2a991",
   "metadata": {
    "papermill": {
     "duration": 0.003528,
     "end_time": "2025-03-10T17:25:42.873151",
     "exception": false,
     "start_time": "2025-03-10T17:25:42.869623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### =======================================================================================\n",
    "#   Create Submission File (Code)      \n",
    "#### ======================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed3749d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T17:25:42.882131Z",
     "iopub.status.busy": "2025-03-10T17:25:42.881705Z",
     "iopub.status.idle": "2025-03-10T17:25:43.149674Z",
     "shell.execute_reply": "2025-03-10T17:25:43.148005Z"
    },
    "papermill": {
     "duration": 0.274689,
     "end_time": "2025-03-10T17:25:43.151645",
     "exception": false,
     "start_time": "2025-03-10T17:25:42.876956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  submission.csv\r\n",
      "\n",
      "Stock code,IsDefault\r\n",
      "X01443,1\r\n",
      "X01444,1\r\n",
      "X01445,1\r\n",
      "X01446,0\r\n",
      "X01447,0\r\n",
      "X01448,1\r\n",
      "X01449,1\r\n",
      "X01450,0\r\n",
      "X01451,0\r\n"
     ]
    }
   ],
   "source": [
    "# Finalize predictions and save submission file\n",
    "sub_fl[target] = np.uint8(mdl_preds_lgbm.round())\n",
    "sub_fl.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "# List the files in the current directory to confirm saving\n",
    "!ls\n",
    "print()\n",
    "\n",
    "# Display the first few rows of the submission file\n",
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e67cc4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T07:18:54.435245Z",
     "iopub.status.busy": "2025-03-10T07:18:54.434852Z",
     "iopub.status.idle": "2025-03-10T07:18:54.446567Z",
     "shell.execute_reply": "2025-03-10T07:18:54.444954Z",
     "shell.execute_reply.started": "2025-03-10T07:18:54.435211Z"
    },
    "papermill": {
     "duration": 0.003728,
     "end_time": "2025-03-10T17:25:43.159486",
     "exception": false,
     "start_time": "2025-03-10T17:25:43.155758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"text-align:center; color:#4CAF50; font-size:36px; font-weight:bold;\">✅ Conclusion</h1>\n",
    "\n",
    "<p style=\"font-size:18px; line-height:1.6; color:#333;\">In this notebook, we successfully developed a machine learning pipeline using <b>LightGBM</b> to tackle the <b><a href=\"https://www.kaggle.com/competitions/stock-pledge-financing-default-prediction/overview\" target=\"_blank\" style=\"color:#4CAF50; text-decoration:none;\">\n",
    "        Stock Pledge Financing Default Prediction\n",
    "    </a>\n",
    "</h1></b> challenge. Here's a summary of our approach and key takeaways:</p>\n",
    "\n",
    "<hr style=\"border:1px solid #ccc; margin:20px 0;\">\n",
    "\n",
    "<h2 style=\"color:#FF5722; font-size:28px;\">Key Highlights</h2>\n",
    "\n",
    "<ul style=\"font-size:16px; color:#555; line-height:1.8;\">\n",
    "    <li><b> Data Processing:</b>  \n",
    "        <ul>\n",
    "            <li>Efficiently handled missing values and encoded categorical variables.</li>\n",
    "            <li>Standardized column names and ensured consistent indexing for clean data handling.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b>Model Training:</b>  \n",
    "        <ul>\n",
    "            <li>Implemented <b>Stratified K-Fold Cross-Validation</b> to ensure robust and reliable model performance.</li>\n",
    "            <li>Optimized the probability threshold for each fold to maximize the <b>F1 Score</b>.</li>\n",
    "            <li>Achieved an overall <b>F1 Score</b> of <code style=\"color:#4CAF50; font-weight:bold;\"> 0.9924</code> on the validation data.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b> Submission:</b>  \n",
    "        <ul>\n",
    "            <li>Final predictions were rounded and saved in the required format for submission.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<hr style=\"border:1px solid #ccc; margin:20px 0;\">\n",
    "\n",
    "<h2 style=\"color:#3F51B5; font-size:28px;\">Possible Improvements</h2>\n",
    "\n",
    "<ol style=\"font-size:16px; color:#555; line-height:1.8;\">\n",
    "    <li><b>Hyperparameter Tuning</b>:  \n",
    "        <span>Leverage techniques like <b>Grid Search</b> or <b>Optuna</b> for more refined model tuning.</span>\n",
    "    </li>\n",
    "    <li><b>Feature Engineering</b>:  \n",
    "        <span>Explore new features, create interaction terms, or apply dimensionality reduction techniques.</span>\n",
    "    </li>\n",
    "    <li><b>Advanced Threshold Optimization</b>:  \n",
    "        <span>Implement sophisticated techniques to fine-tune the optimal threshold across folds.</span>\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<hr style=\"border:1px solid #ccc; margin:20px 0;\">\n",
    "\n",
    "<h2 style=\"color:#009688; font-size:28px;\"> Final Thoughts</h2>\n",
    "\n",
    "<p style=\"font-size:16px; line-height:1.6; color:#555;\">\n",
    "    This solution is a strong starting point, and I'm excited to see how it performs on the leaderboard. The focus was on building a clean and efficient pipeline that could be iteratively improved upon.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; line-height:1.6; color:#555;\">\n",
    "    If you found this notebook helpful or insightful, an upvote would be greatly appreciated! \n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-style:italic; color:#555;\">\n",
    "    Good luck to everyone participating in the competition. Let's keep learning and building! \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa9b44",
   "metadata": {
    "papermill": {
     "duration": 0.003521,
     "end_time": "2025-03-10T17:25:43.166892",
     "exception": false,
     "start_time": "2025-03-10T17:25:43.163371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11184517,
     "sourceId": 93998,
     "sourceType": "competition"
    },
    {
     "datasetId": 5828914,
     "sourceId": 10823884,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.555387,
   "end_time": "2025-03-10T17:25:44.193181",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-10T17:25:27.637794",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
